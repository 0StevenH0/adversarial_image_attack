# adversarial_image_attack
<p> Do an adversarial attack on image that causes deep learning model unable to predict the image correctly using imagenet dataset, then tries to fix this without 
adding adversarial image onto training </p>
<p> Dataset link : https://www.kaggle.com/datasets/lijiyu/imagenet </p>
<p> project date : 09/2023 - current date</p>
